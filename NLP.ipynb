{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c2a9b2c-4fad-4d48-afc3-04d0b5d1ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16050c0-3ede-496a-b51d-7a50190b9452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()\n",
    "    \n",
    "print(shakespeare_text[:148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec4426f-4ad3-4260-bd11-6facf98dc2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0caffcdc-be0a-4d95-8320-fc5568a5f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e07c73a6-3b40-4d3a-96f5-cc85111397b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to Sequences:  [[20, 6, 9, 8, 3]]\n",
      "Sequences to Text:  ['f i r s t']\n"
     ]
    }
   ],
   "source": [
    "print(\"Text to Sequences: \", tokenizer.texts_to_sequences([\"First\"]))\n",
    "\n",
    "print(\"Sequences to Text: \", tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495364bf-ba3d-49d2-9e66-a7e01464768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of distinct characters:  39\n",
      "total number of characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "print(\"number of distinct characters: \", max_id)\n",
    "dataset_size = tokenizer.document_count # total number of characters\n",
    "print(\"total number of characters: \", dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f910d942-ac30-452a-a163-a07753ece28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622f5994-6760-4569-97db-e6ff1c24c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06e5f7a-27d2-4f42-b69d-6ba52149c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f42d318-1094-4518-86e3-0199f5fff55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "169b24c9-062f-465a-b466-6fd2d2c11f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x00000192B0EE3C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x00000192B0EE3C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadf89a9-bab4-4c73-8bdd-672b7880c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d73506d-1ad0-4387-a869-664c76bb1a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 39) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c08929a5-b4c6-445c-80ee-e35c53d80513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31368/31368 [==============================] - 3300s 105ms/step - loss: 1.6206\n",
      "Epoch 2/10\n",
      "31368/31368 [==============================] - 3278s 105ms/step - loss: 1.5341 - lo\n",
      "Epoch 3/10\n",
      "31368/31368 [==============================] - 3221s 103ms/step - loss: 1.5124\n",
      "Epoch 4/10\n",
      "31368/31368 [==============================] - 3253s 104ms/step - loss: 1.5002\n",
      "Epoch 5/10\n",
      "31368/31368 [==============================] - 3255s 104ms/step - loss: 1.4926\n",
      "Epoch 6/10\n",
      "31368/31368 [==============================] - 3277s 104ms/step - loss: 1.4877\n",
      "Epoch 7/10\n",
      "31368/31368 [==============================] - 3285s 105ms/step - loss: 1.4834\n",
      "Epoch 8/10\n",
      "31368/31368 [==============================] - 3317s 106ms/step - loss: 1.4805\n",
      "Epoch 9/10\n",
      "31368/31368 [==============================] - 3350s 107ms/step - loss: 1.4777\n",
      "Epoch 10/10\n",
      "31368/31368 [==============================] - 3240s 103ms/step - loss: 1.4759\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=10)\n",
    "model.save('char_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2538275-be85-46df-9b81-67af072ac49d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('char_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5b04a45-7127-4f5f-b857-54fbbf01d2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)\n",
    "\n",
    "X_new = preprocess([\"How are yo\"])\n",
    "#Y_pred = model.predict_classes(X_new)\n",
    "Y_pred = np.argmax(model(X_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4766135b-71c5-41a3-b8b9-196e1bdf5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f6e1757-208b-4338-b1f3-edcf8934ef53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the devilish state,\n",
      "and that i can be so a suitors \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b06b19db-c912-498e-89b8-733a8089b51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be to be gone.\n",
      "\n",
      "gremio:\n",
      "what, hold you now, sir, i \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"b\", temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c1e88-aee2-4393-87f3-a327814cf05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
